{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Recognizing hand-written digits\n",
    "\n",
    "\n",
    "An example showing how the scikit-learn can be used to recognize images of\n",
    "hand-written digits.\n",
    "\n",
    "This example is commented in the\n",
    "`tutorial section of the user manual <introduction>`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        88\n",
      "          1       0.99      0.97      0.98        91\n",
      "          2       0.99      0.99      0.99        86\n",
      "          3       0.98      0.87      0.92        91\n",
      "          4       0.99      0.96      0.97        92\n",
      "          5       0.95      0.97      0.96        91\n",
      "          6       0.99      0.99      0.99        91\n",
      "          7       0.96      0.99      0.97        89\n",
      "          8       0.94      1.00      0.97        88\n",
      "          9       0.93      0.98      0.95        92\n",
      "\n",
      "avg / total       0.97      0.97      0.97       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADuCAYAAAAZZe3jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEq1JREFUeJzt3X2QXfVdx/HPB0JFBXYTK7a0kOVhtFrbhId2ptgxwYJWKd2gAkPbkaBAOh3Hon0gf0ATWipBwQYdsSmt7CCtkjCaFGaQEs2mBYUWysYpVGnJA88MEHYJD2KBn3+cm3JJkz3f3T13935v3q8ZZvbmfu/vnPvdez97zr3nx8+lFAEA8thnpncAADAxBDcAJENwA0AyBDcAJENwA0AyBDcAJJMyuG3va/s524c1WQt620n0tnP2tt5OS3C3mrTzv1dtv9h2+8MTHa+U8kop5YBSyoNN1jbB9qdsP257zPaXbb+hw9vbK3pre57tb9h+2vbLnd5ea5t7S2//0PZ3bT9r+2Hbl9ret8Pb3Ft6+2Hb/9PKgydsX2P7gCmPO90TcGxvlXROKWX9ODWzSinT8uZsku2TJX1F0gmSnpC0TtLGUsqF07T9rerd3v6ypPdIGpW0upQya5q3v1W929uPSdok6TuSDpZ0k6TrSimXT9P2t6p3e3uYpBdKKU/ZPlDS1ZIeLaX82VTG7YqPSmxfYvt62/9oe4ekj9h+j+07bI/afsz2X9ver1U/y3axPdC6fV3r/ptt77D9n7YPn2ht6/7ftn1/6y/k39i+3fbi4FM5S9KXSinfL6Vsl3SJpOhjO6JXetvq6d9Luq/B9kxJD/X2qlLK7aWU/yulPCzpa5J+rblOTVwP9fbBUspTbf/0qqSjptqfrgjullNVvWD6JF0v6WVJH5f0RlUvovdLWjLO4z8k6SJJcyQ9KOlzE621fbCk1ZI+1druFknv3vkg24e3XjSH7GHct6s6ctlpk6S32O4bZ1+mQy/0tlv1Ym9/XdK9wdpO6one2l5ge0zSs5I+KGnlOPsR0k3BfVsp5cZSyqullBdLKd8ppdxZSnm5lLJZ0pckLRjn8TeUUu4qpfxI0lclzZ9E7QckjZRS1rXu+4KkH/+1LKVsKaX0l1Ie3cO4B0gaa7u98+cDx9mX6dALve1WPdVb2+dKeqekv6qrnQY90dtSysZSSp+kQyVdruoPw5RM6+eENR5qv2H7bZKukHSspJ9Rta93jvP4x9t+fkFViE609pD2/SilFNsP1+75a56TdFDb7Z0/75jAGJ3QC73tVj3TW9u/p+pI832tj/pmWs/0tvXYh22vV3UW8e66+vF00xH3rt+SrpL0PUlHlVIOkvQZSe7wPjwm6a07b9i2pLdM4PH3SprXdnuepEdKKWN7qJ8uvdDbbtUTvXX1xfrfSTq5lNINH5NIPdLbXcySdORUd6qbgntXB6r6qOF5V1cUjPdZVlNuknSM7VNsz1L1edrPT+Dx10o61/bbbM+WdKGkoeZ3c8rS9daV/SW9oXV7f3f4UstJytjbk1S9dk8tpdzdoX1sQsbefsT2oa2fB1Sd0fzbVHeqm4P7E6qu0tih6i/t9Z3eYCnlCUlnqPp872lVfxnvkfSSJNk+wtV1prv9IqKUcpOqz8C+KWmbpB9I+myn93sS0vW2Vf+iqi9892393DVXmLTJ2NvPqPoC8Ba/di31jZ3e70nI2Nt3SLrD9vOSblN1Vj7lPzjTfh13Jq4mITwq6fdLKd+a6f3pJfS2c+ht53RLb7v5iHtG2H6/7X7bP6Xq8qAfSfr2DO9WT6C3nUNvO6cbe0tw/6T3Stos6UlJv6Xqc7+XZnaXega97Rx62zld11s+KgGAZDjiBoBkOjUBp5HD+DVr1tTWXHDBBbU1J510Umh7K1asqK2ZPXt2aKyAyV5/Om2nSAsXLqytGR0dDY118cUX19YMDg6Gxgro+t4ODw/X1ixatCg01vz5400IjG8vaCrXTTfS38suu6y2ZunSpbU1hx9+eG2NJN19d/0VktOdCxxxA0AyBDcAJENwA0AyBDcAJENwA0AyBDcAJENwA0AyBDcAJNNNK+D8hMjkmi1bttTWPPPMM6HtzZkzp7Zm9erVtTWnnXZaaHvdrr+/v7Zm48aNobE2bNhQW9PgBJwZNTIyUltzwgkn1Nb09cWWKt26dWuoLoPIxJnIe3DVqlW1NUuWxP7vqpEJOCeeeGJorKZwxA0AyRDcAJAMwQ0AyRDcAJAMwQ0AyRDcAJAMwQ0AyRDcAJDMjE3AiVzUHplc88ADD9TWHHHEEaF9iqyUE9nvDBNwIpNEGlw1JbRKS69Yu3Ztbc28efNqa6Ir4ERWF8rivPPOq62JTMw79thja2uiK+BM9+SaCI64ASAZghsAkiG4ASAZghsAkiG4ASAZghsAkiG4ASAZghsAkpmxCTiRVWmOOeaY2pro5JqIyEX7GaxcubK2Zvny5bU1Y2NjDexNZeHChY2N1e3OP//82pqBgYFGxpF6Z+UgKfZ+3rx5c21NZPJedGJNJKtmz54dGqspHHEDQDIENwAkQ3ADQDIENwAkQ3ADQDIENwAkQ3ADQDIENwAk09UTcCIr0jSpGy+0n4zIxI3FixfX1jT5XEdHRxsbayZFnkdkAlRklZyooaGhxsbKIDJJZ/v27bU10Qk4kbr169fX1jT5fuKIGwCSIbgBIBmCGwCSIbgBIBmCGwCSIbgBIBmCGwCSIbgBIBmCGwCSmbGZk5FZRHfffXcj24rMiJSku+66q7bm9NNPn+ru7JVGRkZqa+bPnz8NezI1kSXfrrzyyka2FZ1d2d/f38j2ekkkXyKzHSVpyZIltTWXXXZZbc2KFStC24vgiBsAkiG4ASAZghsAkiG4ASAZghsAkiG4ASAZghsAkiG4ASCZGZuAE1l+KDIhZs2aNY3URF1wwQWNjYV8Iku+DQ8P19Zs2rSptmbRokWBPZIGBwdra84+++xGxukGS5cura2JLDcWnZh366231tZM98Q8jrgBIBmCGwCSIbgBIBmCGwCSIbgBIBmCGwCSIbgBIBmCGwCS6eoJOJFVJSITYo477rjQPjW14k4GkVVTIhMy1q1bF9peZFJKZHLLTIus0hNZ7SdSE1ltR4r9DgYGBmprskzAiaxuc9555zW2vcjkmlWrVjW2vQiOuAEgGYIbAJIhuAEgGYIbAJIhuAEgGYIbAJIhuAEgGYIbAJJxKWWm9wEAMAEccQNAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACSTKrhtD9gutme1bt9s+6xJjHOY7eds79v8XuZEbzuL/nbOXtnbUkqj/0naKulFSc9JekLSkKQDGhp7QFKRNGsS+3Ri0881uO35kr4laUzSw5Iuorfd11v6O+4+LGjt+yX0trGeHi/p25J2SPovSe+dyOM7dcR9SinlAEnHSDpO0oW7FriS6oh/kr4m6ZuS5qh6A3zM9genMB69fU3TvZXo7+vY3k/SlZLubGA4eivJ9hxJN0r6S0n9kv5C0o22Z0fH6GiDSimPSLpZ0q9Kku1h25+3fbukFyQdYbvP9ldsP2b7EduX7DxVsb2v7cttP2V7s6ST28dvjXdO2+1zbX/f9g7b99k+xvY/SDpMVWOes/3p3ZxaHWL767a32/6h7XPbxlxue7Xta1vj3mv7uAm0YUDSV0spr5RSHpB0m6S3T7ybr0dvJXWotxL9bfMJSd+Q9N8T7eGe0FsdL+nxUsqa1mv3OklPSvrdiTSx6VOArWqdfkg6VNK9kj7Xuj0s6UFVb65ZkvaT9C+SVkn6WUkHqzp9WNKq/6iqF8yhqo6qNqjtlKg13jmtn0+T9Iikd0mypKMkzd3dKZF2ObVSddR2laT9VZ1+PynpN1r3LZf0v5J+R9K+ki6VdEfbWFdJumqcfvy5pBWt5/pLqk7p30Vvu6u39He3/Zgr6X5JB6j6aGOqH5XQ2+q+D0i6b5d/+4GkL4T7OdlfRM0v6DlJo5K2tZ7AT7c19LNttb8g6aWd97f+7UxJG1o//7ukj7bd95vj/IJukfTxuhfNrr+g1i//FUkHtt1/qaShtl/Q+rb7fkXSixPox/GSfijp5dY2L6a33ddb+rvbba+TdEbr5yFNPbjpbVX7c60+nKnqj9RZkl6VtCraz1nqjEWllPV7uO+htp/ntnb8Mds7/22ftppDdqnfNs42D5X0wMR3VYdI2l5K2bHLdtpPex5v+/kFSfvbnlVKeXm8gV19lvWvkv5Y1eexb5J0g+0nSilXTWJfJXorqWO9leivJMn2KapC6/pJ7Nee0FtJpZSnbQ9KulzS36r647Je1RljSKeCezyl7eeHVP1lfeMenuxjqhq/02HjjPuQpCMD29zVo5Lm2D6w7Zd0mKrTq6k6QtIrpZRrW7cftv1Pqk6vphIue0JvO9dbae/q7/skHWd7Zzj1SXrF9jtKKYMNjL+rvam3KqVsVPXxjVqfqW+WdEX08TP67W0p5TFVX3xcYfsg2/vYPtL2glbJakl/Yvutrr5xXTrOcF+W9Enbx7pylO25rfueUPVG390+PCTpPyRdant/2++U9EeSrmvgKd6v6ovyD7We25sknaHq8p+OoredtRf09yJJv6jqs935kr4u6WpJZzcw9rj2gt7K9tG297N9kKoj74dKKbdEH98Nl938gaQ3SLpP0jOSbpD05tZ9V6s6jdgk6buS/nlPg5RS1kj6vKrT5h2S1qr64kKqPpu60Pao7U/u5uFnqvp861FVX4osG+eU7nVsf9H2F/ewT8+q+qb4T1vPbUTS9yRdEhm7AfS2s3q5vztKKY/v/E/VNdjPl1K2R8ZuQM/2tuXTkp5SdUbwZkmnRsb98fitD8sBAEl0wxE3AGACCG4ASIbgBoBkCG4ASKZT13E38o3n6Ohobc3ixYtra0ZGRhrb3vDwcG3N/PnzI5tzfcluNdLboaGh2prly5fX1mzbNt7ch9esXbu2tmZwsLHLg2e0txGR19GiRYtCY61cubK2JvI+CZpsb6VpzIXIazfyHpCkhQsXNrK9JnOBI24ASIbgBoBkCG4ASIbgBoBkCG4ASIbgBoBkCG4ASIbgBoBkZmIhBUmxi+gjF75v2rSptmbBggW1NZK0cePG2prIRJLghfYds3Xr1tqas8/u+P9W+XW2bNkyrdvrdueff35tzcDAQGis6ESdXhF5vpH3YOR9IjU3ya/JXOCIGwCSIbgBIBmCGwCSIbgBIBmCGwCSIbgBIBmCGwCSIbgBIJkZm4ATWbUjMrlmw4YNtTXRC+0jE3COPvro0Fjdrq+vr7ZmbGyskXGkvWuSSFOv7eikpf7+/lBdr4hM3otMXopMppOkdevW1dZM96Q7jrgBIBmCGwCSIbgBIBmCGwCSIbgBIBmCGwCSIbgBIBmCGwCSmbEJOJGJLJHJHZHJDtEJOHPnzq2tGRwcDI01kyKTDyJ9a3KVnMhkh8iqMDNteHi4tmb58uW1NcuWLautia6AE5kgkuF1GxV57Q4NDdXWRHMhkkOR1bqaxBE3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMi6ldGLcRgaNXCC/ePHi2prIyjaSNG/evNqakZGR0FgBnuTjGultZHJHZFJBdOJBZDLPPffcU1sTXGmkY72NrOQTeY1EaqIrtER6GxkrOElnsr2VGnrtTrfIazySQ5EaBfvLETcAJENwA0AyBDcAJENwA0AyBDcAJENwA0AyBDcAJENwA0AyBDcAJDNjS5dFRGb3jY6ONra9TZs21dZElkQKzpDqmEhPtm3bVlsTWUosOJMxNLsvsixYdHuTEelbZJmwyBJ4kRmY0Rm/EZF96gaRZd/6+/tra5pcBi8yy3X27NmNbS+CI24ASIbgBoBkCG4ASIbgBoBkCG4ASIbgBoBkCG4ASIbgBoBkunoCTkRk0kyTmpzw0ymRCQpnnXVWbU1kMkRUX19fbU10GbROaapvkSX3IpPLohNwIvvUyYlLTYpMnGlq+bjoRLmxsbHamume4MQRNwAkQ3ADQDIENwAkQ3ADQDIENwAkQ3ADQDIENwAkQ3ADQDIupXRi3I4MujuRi/EjEyKk2ASMtWvXNjKOJEeKdqOR3kYmKER6G1lJR5Kuueaa2poGVw6a0d5GRFZSiqwaJElbtmyprYlM+AmabG+laexvZMJRdPLesmXLamsanKwW6i9H3ACQDMENAMkQ3ACQDMENAMkQ3ACQDMENAMkQ3ACQDMENAMl0agIOAKBDOOIGgGQIbgBIhuAGgGQIbgBIhuAGgGQIbgBIhuAGgGQIbgBIhuAGgGQIbgBIhuAGgGQIbgBIhuAGgGQIbgBIhuAGgGQIbgBIhuAGgGQIbgBIhuAGgGQIbgBIhuAGgGQIbgBIhuAGgGT+H65gYDsww8LzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Author: Gael Varoquaux <gael dot varoquaux at normalesup dot org>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.fetch_mldata(\"MNIST Original\")\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples // 2:]\n",
    "predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
